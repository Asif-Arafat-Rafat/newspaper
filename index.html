<!DOCTYPE html>
<html lang="en">
<head>
    <title>Document</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div class="news fnews" >
    <h1>Flipping Out for the M1</h1>
    <h4 class="snippet">
        The M1, a Flipper Zero alternative, offers similar capabilities and a professional design at a lower price â€” if you can wait until July.
    </h4>
        <div class="minews">
            <p>
                The Flipper Zero is an innovative and versatile hacking tool designed for both cybersecurity professionals and hobbyists alike. Developed by Flipper Devices, it is a compact and multifunctional device that combines various capabilities into a single sleek package. At its core, the Flipper Zero is equipped with a microcontroller and several types of transceivers, allowing users to perform a wide array of tasks ranging from penetration testing to hardware manipulationThe Flipper Zero is an innovative and versatile hacking tool designed for both cybersecurity professionals and hobbyists alike. Developed by Flipper Devices, it is a compact and multifunctional device that combines various capabilities into a single sleek package. At its core, the Flipper Zero is equipped with a microcontroller and several types of transceivers, allowing users to perform a wide array of tasks ranging from penetration testing to hardware manipulation.
                <span >
                    Beyond its technical capabilities, the Flipper Zero distinguishes itself with its user-friendly interface and open-source software. Its intuitive interface and customizable firmware make it accessible to users of all skill levels, while its open-source nature encourages collaboration and community-driven development. This combination of accessibility and flexibility positions the Flipper Zero as a powerful tool for both educational purposes and real-world cybersecurity applications.
        
                    <br><br> The device has captured a lot of attention in recent months for some notable hacks that were carried out while leveraging its capabilities. We reported on one particularly annoying attack that was targeted at a wide range of Apple devices last year.
                    
                    <br><br> If you are looking for an alternative to the Flipper Zero, until recently that probably meant buying a drawer full of devices at a much higher overall cost and lacking in simplicity and usability. But now an ongoing Kickstarter campaign is offering a device, called the M1, with functionality and a form factor suspiciously similar to the Flipper Zero. At least for now, the M1 comes with a lower price tag â€” at the time of writing, a $109 early bird special is still available. This is in comparison to the $169 charged for a Flipper Zero in the Flipper store. The retail price of the M1 is listed as $165, however, so those savings may evaporate in the future.
                </span>
                <button class="morebtn" onclick="seeMore(this)">View</button>  
            </p>
            <img src="https://hackster.imgix.net/uploads/attachments/1682167/a41c855ce3d521ea9945e4546cd0fd15_original_FlknyDU5zI.jpg?auto=compress%2Cformat&w=830&h=466.875&fit=min&dpr=1" alt="">
        </div>

    </div>
    <div class="news" >
        <h1>Google's Bard Gen AI Is Now Gemini</h1>
        <h4 class="snippet">
            Bard and Duet AI branding ditched in favor of Gemini, while a new Gemini Advanced platform offers better results â€” at a price.
        </h4>
        <div class="minews">
            <p>
                Google has announced the end of its Bard generative artificial intelligence (AI) program, relaunching it under the new name Gemini while also announcing access to a new model dubbed Gemini Ultra 1.1 â€” the first, it claims, to outperform human experts across a range of fields."For years, weâ€™ve been investing deeply in AI as the single best way to improve Search and all of our products," claims Sundar Pichai, chief executive officer for both Google and its parent company Alphabet. "In December, we took a significant step on our journey to make AI more helpful for everyone with the start of the Gemini era, setting a new state of the art across a wide range of text, image, audio, and video benchmarks."
                <span>
                    Google has announced the end of its Bard generative artificial intelligence (AI) program, relaunching it under the new name Gemini while also announcing access to a new model dubbed Gemini Ultra 1.1 â€” the first, it claims, to outperform human experts across a range of fields.
        
                    "For years, weâ€™ve been investing deeply in AI as the single best way to improve Search and all of our products," claims Sundar Pichai, chief executive officer for both Google and its parent company Alphabet. "In December, we took a significant step on our journey to make AI more helpful for everyone with the start of the Gemini era, setting a new state of the art across a wide range of text, image, audio, and video benchmarks."
        
                    <br><br> Google has ended Bard's reign with the launch of Gemini, under which its generative AI efforts will be pushed forward. (ðŸ“¹: Google)
        
                    <br><br> While December may have been the launch of the "Gemini era," for end users little changed: the primary way users interacted with Google's generative AI offerings was through Bard, a large language model (LLM) chatbot that aimed to compete with OpenAI's popular ChatGPT. Now, though, Bard is no more â€” supplanted by Gemini, under which branding the service will be made available in a dedicated Android app and on the Google app for Apple's iOS.
        
                    <br><br> "The largest [Gemini] model, Ultra 1.0, is the first to outperform human experts on MMLU (massive multitask language understanding), which uses a combination of 57 subjects â€” including math, physics, history, law, medicine and ethics â€” to test knowledge and problem-solving abilities," Pichai claims of the company's progress in its battle with OpenAI. "Today we're taking our next step and bringing Ultra to our products and the world."
                    
                    <br><br> Gemini Ultra 1.0, Pichai explains, is being made available to end users for the first time as Gemini Advanced â€” replacing the smaller Gemini Pro 1.0 model, but only for those subscribing to the new Google One AI Premium plan. "With our Ultra 1.0 model," Google's Sissie Hsiao, vice president and general manager for Gemini experiences and Google Assistant, claims, "Gemini Advanced is far more capable at highly complex tasks like coding, logical reasoning, following nuanced instructions and collaborating on creative projects.
                    
                    <br><br> "Gemini Advanced not only allows you to have longer, more detailed conversations; it also better understands the context from your previous prompts."
                </span>
                <button class="morebtn" onclick="seeMore(this)">View</button>  
            </p>
            <img src="https://hackster.imgix.net/uploads/attachments/1683028/image_eX6OWFGJTR.png?auto=compress%2Cformat&w=830&h=466.875&fit=min&dpr=1" alt="">
        </div>

    </div>
    <div class="news" >
        <h1>Robots Get X-Ray Vision</h1>
        <h4 class="snippet">
            You don't want to play hide-and-seek with a robot powered by THOR, which uses human-inspired reasoning to locate partially hidden objects.
        </h4>
        <div class="minews">
            <p>
                Object recognition is one of the most crucial ingredients in robot visual perception, playing a pivotal role in enabling robots to interact with their environment. This capability assists robots in identifying and categorizing objects in their surroundings, much like how humans recognize familiar objects. Advancing this technology is of immense importance for a variety of applications across industries, from manufacturing and logistics to healthcare and household assistance.A mature object recognition algorithm facilitates common tasks such as navigation, manipulation, and interaction. By accurately identifying objects, robots can make informed decisions and execute tasks more efficiently. For instance, in industrial settings, robots equipped with robust object recognition systems can precisely locate and grasp items on assembly lines, streamlining production processes and enhancing productivity.
                <span>
                    
                    <br><br>Technological advancements have significantly bolstered object recognition capabilities in recent years. Machine learning algorithms, particularly deep learning models, have revolutionized this field by enabling robots to learn from vast amounts of data, thereby improving their accuracy and robustness in recognizing objects across diverse contexts. Convolutional neural networks have emerged as a particularly powerful tool in object recognition tasks, allowing robots to detect and classify objects with remarkable accuracy.
                    
                    <br><br>Despite these advancements many challenges persist, particularly in scenarios involving partially occluded objects. Existing systems often struggle to recognize objects when they are only partially visible, a task that humans can typically perform effortlessly. Research in this area has recently been given a boost by a team at the University of Washington. They have developed a system called Topological features of point cloud slices for Human-inspired Object Recognition (THOR) that reconstructs the three-dimensional shape of a partially-visible object to determine what it is most likely to be.
                    
                    <br><br>THOR was modeled on a reasoning mechanism called object unity that humans use to recognize occluded objects. Using this mechanism, people mentally rotate objects in their mind to match representations stored in their memory, then associate the visible portion of the object with the full, unoccluded object that they have previously seen. To simulate that process, THOR first creates a three-dimensional representation of an object, in the form of a point cloud, using an image from a depth camera as the input. The view of each point cloud is then normalized before a machine learning classifier is leveraged to predict the most likely object that is present.
                    
                </span>
                <button class="morebtn" onclick="seeMore(this)">View</button> 
            </p>
            <img src="https://hackster.imgix.net/uploads/attachments/1682669/robotinlab-scaled_VBqz2nneDV.jpg?auto=compress%2Cformat&w=830&h=466.875&fit=min&dpr=1" alt="">
        </div>
    </div>


</body>
<script src="script.js"></script>
</html>